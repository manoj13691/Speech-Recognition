{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "K.set_image_dim_ordering('th')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"words list represents the \"pkl\" file names\n",
    "    which have the same word as .wav file.\n",
    "    The pkl file is dictionary with key as the word spoken\n",
    "    and the value as numpy array where element is a (20 * 100) vector\n",
    "    representing the mfcc vectors of the .wav file. \"\"\"\n",
    "\n",
    "words = [\"bed\", \"down\", \"dog\", \"eight\", \"four\", \"cat\",\"go\",\"bird\",\"five\"]\n",
    "#words = [\"bed\", \"down\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18735, 20, 100)\n",
      "(18735, 1)\n",
      "[['bed']\n",
      " ['bed']\n",
      " ['bed']\n",
      " ..., \n",
      " ['five']\n",
      " ['five']\n",
      " ['five']]\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load( open( words[0]+\".pkl\", \"rb\" ) )\n",
    "for keys in data:\n",
    "    X = data[keys]\n",
    "    Y = np.array([[keys]] * data[keys].shape[0])\n",
    "    #print X_1.shape\n",
    "    \n",
    "    \n",
    "for i in range(1,len(words)):\n",
    "    data = pickle.load( open( words[i]+\".pkl\", \"rb\" ) )\n",
    "    for keys in data:\n",
    "        Y = np.append(Y, [[keys]] * data[keys].shape[0], axis = 0)\n",
    "        X = np.append(X, data[keys], axis = 0)\n",
    "        #print X_1.shape\n",
    "        \n",
    "print X.shape\n",
    "print Y.shape\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(Y)\n",
    "#print integer_encoded\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "Y = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18735, 1, 20, 100)\n",
      "(18735, 9)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Convolution Layer in Keras\n",
    "   accepts input as 3d - height, width, depth(RGB channels).\n",
    "   Since we do not have depth in text, we can convert it to a vector\n",
    "   with a depth = 1\"\"\"\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, 20, 100)\n",
    "print X.shape\n",
    "print Y.shape\n",
    "num_classes = Y.shape[1]\n",
    "print num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 20, 100), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 16, 96)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 8, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 6, 46)         4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 3, 23)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 3, 23)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1035)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               132608    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 459       \n",
      "=================================================================\n",
      "Total params: 144,362\n",
      "Trainable params: 144,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16861 samples, validate on 1874 samples\n",
      "Epoch 1/1\n",
      "16832/16861 [============================>.] - ETA: 0s - loss: 1.2897 - acc: 0.5688Epoch 00000: val_loss improved from inf to 2.52748, saving model to CNN_val_loss.hdf5\n",
      "16861/16861 [==============================] - 136s - loss: 1.2880 - acc: 0.5695 - val_loss: 2.5275 - val_acc: 0.1419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72725e4990>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=\"CNN_val_loss.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "model.fit(X, Y, validation_split=0.1, callbacks=callbacks_list, epochs=1, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16861 samples, validate on 1874 samples\n",
      "Epoch 1/3\n",
      "16832/16861 [============================>.] - ETA: 0s - loss: 0.3815 - acc: 0.8724Epoch 00000: val_loss improved from 0.63535 to 0.51391, saving model to CNN_val_loss.hdf5\n",
      "16861/16861 [==============================] - 118s - loss: 0.3821 - acc: 0.8724 - val_loss: 0.5139 - val_acc: 0.8453\n",
      "Epoch 2/3\n",
      "16832/16861 [============================>.] - ETA: 0s - loss: 0.3279 - acc: 0.8881Epoch 00001: val_loss did not improve\n",
      "16861/16861 [==============================] - 116s - loss: 0.3277 - acc: 0.8882 - val_loss: 0.7578 - val_acc: 0.7785\n",
      "Epoch 3/3\n",
      "16832/16861 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.9000Epoch 00002: val_loss did not improve\n",
      "16861/16861 [==============================] - 116s - loss: 0.3000 - acc: 0.8997 - val_loss: 0.8547 - val_acc: 0.7529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7271842e50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.1, callbacks=callbacks_list, epochs=3, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26051461704943474"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(Y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
