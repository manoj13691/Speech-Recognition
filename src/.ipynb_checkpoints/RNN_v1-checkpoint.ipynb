{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import GlobalMaxPooling1D, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1731, 20, 100)\n",
      "(1731, 2)\n",
      "(1713, 20, 100)\n",
      "(1713, 2)\n",
      "(3444, 20, 100)\n",
      "(3444, 2)\n"
     ]
    }
   ],
   "source": [
    "bird_audio_with_label = pickle.load( open( \"bird.txt\", \"rb\" ) )\n",
    "X_bird = bird_audio_with_label[\"bird\"]\n",
    "Y_bird = np.array([[1,0]] * X_bird.shape[0])\n",
    "print X_bird.shape\n",
    "print Y_bird.shape\n",
    "\n",
    "bed_audio_with_label = pickle.load( open( \"bed.txt\", \"rb\" ) )\n",
    "X_bed = bed_audio_with_label[\"bed\"]\n",
    "Y_bed = np.array([[0,1]] * X_bed.shape[0])\n",
    "print X_bed.shape\n",
    "print Y_bed.shape\n",
    "\n",
    "X = np.vstack((X_bird, X_bed))\n",
    "Y = np.vstack((Y_bird, Y_bed))\n",
    "print X.shape\n",
    "print Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 6)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "X_ = np.array([[[1,2,3,4,5,6],[7,8,9,10,11,12]]])\n",
    "Y_ = np.array([[1,0]])\n",
    "#Y = np.array([[[1],[2]]])\n",
    "print X_.shape\n",
    "print Y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 20, 40)            22560     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 22,642\n",
      "Trainable params: 22,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(20,100 ))\n",
    "x = (LSTM(40, return_sequences=True))(inp)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2755 samples, validate on 689 samples\n",
      "Epoch 1/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1743 - acc: 0.9376 - val_loss: 0.6618 - val_acc: 0.7620\n",
      "Epoch 2/60\n",
      "2755/2755 [==============================] - 1s - loss: 0.1687 - acc: 0.9361 - val_loss: 0.6738 - val_acc: 0.7489\n",
      "Epoch 3/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1539 - acc: 0.9434 - val_loss: 0.7069 - val_acc: 0.7388\n",
      "Epoch 4/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1464 - acc: 0.9525 - val_loss: 0.8268 - val_acc: 0.6996\n",
      "Epoch 5/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1770 - acc: 0.9336 - val_loss: 0.7502 - val_acc: 0.7155\n",
      "Epoch 6/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1440 - acc: 0.9546 - val_loss: 0.7278 - val_acc: 0.7373\n",
      "Epoch 7/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1414 - acc: 0.9525 - val_loss: 0.7211 - val_acc: 0.7329\n",
      "Epoch 8/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1326 - acc: 0.9564 - val_loss: 0.7029 - val_acc: 0.7475\n",
      "Epoch 9/60\n",
      "2755/2755 [==============================] - 1s - loss: 0.1319 - acc: 0.9593 - val_loss: 0.7099 - val_acc: 0.7257\n",
      "Epoch 10/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1545 - acc: 0.9470 - val_loss: 0.7384 - val_acc: 0.7199\n",
      "Epoch 11/60\n",
      "2755/2755 [==============================] - 1s - loss: 0.1582 - acc: 0.9426 - val_loss: 0.7104 - val_acc: 0.7242\n",
      "Epoch 12/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1501 - acc: 0.9434 - val_loss: 0.8346 - val_acc: 0.6996\n",
      "Epoch 13/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1361 - acc: 0.9528 - val_loss: 0.8882 - val_acc: 0.6763\n",
      "Epoch 14/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1418 - acc: 0.9481 - val_loss: 0.8839 - val_acc: 0.6981\n",
      "Epoch 15/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1412 - acc: 0.9488 - val_loss: 0.9000 - val_acc: 0.6778\n",
      "Epoch 16/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1265 - acc: 0.9583 - val_loss: 1.0267 - val_acc: 0.6255\n",
      "Epoch 17/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1197 - acc: 0.9593 - val_loss: 0.7988 - val_acc: 0.7170\n",
      "Epoch 18/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1176 - acc: 0.9652 - val_loss: 0.9206 - val_acc: 0.6705\n",
      "Epoch 19/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1221 - acc: 0.9575 - val_loss: 0.8714 - val_acc: 0.6880\n",
      "Epoch 20/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1281 - acc: 0.9546 - val_loss: 0.9387 - val_acc: 0.6633\n",
      "Epoch 21/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1214 - acc: 0.9568 - val_loss: 0.8164 - val_acc: 0.7199\n",
      "Epoch 22/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1117 - acc: 0.9623 - val_loss: 0.9031 - val_acc: 0.6894\n",
      "Epoch 23/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1280 - acc: 0.9546 - val_loss: 0.9810 - val_acc: 0.6633\n",
      "Epoch 24/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1115 - acc: 0.9597 - val_loss: 0.9099 - val_acc: 0.6720\n",
      "Epoch 25/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1045 - acc: 0.9637 - val_loss: 0.8472 - val_acc: 0.6880\n",
      "Epoch 26/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0973 - acc: 0.9681 - val_loss: 0.9211 - val_acc: 0.6749\n",
      "Epoch 27/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1056 - acc: 0.9626 - val_loss: 0.8345 - val_acc: 0.7112\n",
      "Epoch 28/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1089 - acc: 0.9619 - val_loss: 0.9390 - val_acc: 0.6778\n",
      "Epoch 29/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1036 - acc: 0.9670 - val_loss: 1.0013 - val_acc: 0.6662\n",
      "Epoch 30/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1087 - acc: 0.9615 - val_loss: 0.9825 - val_acc: 0.6749\n",
      "Epoch 31/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1076 - acc: 0.9626 - val_loss: 0.8880 - val_acc: 0.7025\n",
      "Epoch 32/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1075 - acc: 0.9608 - val_loss: 0.9254 - val_acc: 0.6821\n",
      "Epoch 33/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1055 - acc: 0.9630 - val_loss: 0.8744 - val_acc: 0.6923\n",
      "Epoch 34/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0885 - acc: 0.9695 - val_loss: 0.9954 - val_acc: 0.6821\n",
      "Epoch 35/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0902 - acc: 0.9699 - val_loss: 1.0131 - val_acc: 0.6880\n",
      "Epoch 36/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0989 - acc: 0.9659 - val_loss: 1.0817 - val_acc: 0.6502\n",
      "Epoch 37/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0981 - acc: 0.9688 - val_loss: 0.9945 - val_acc: 0.6792\n",
      "Epoch 38/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0969 - acc: 0.9677 - val_loss: 1.2791 - val_acc: 0.5980\n",
      "Epoch 39/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1296 - acc: 0.9510 - val_loss: 1.2623 - val_acc: 0.5980\n",
      "Epoch 40/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1347 - acc: 0.9474 - val_loss: 0.9744 - val_acc: 0.6807\n",
      "Epoch 41/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1051 - acc: 0.9626 - val_loss: 0.9887 - val_acc: 0.6778\n",
      "Epoch 42/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1206 - acc: 0.9499 - val_loss: 0.9986 - val_acc: 0.6734\n",
      "Epoch 43/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1095 - acc: 0.9604 - val_loss: 0.9723 - val_acc: 0.6836\n",
      "Epoch 44/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1023 - acc: 0.9641 - val_loss: 1.0068 - val_acc: 0.6749\n",
      "Epoch 45/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0960 - acc: 0.9652 - val_loss: 1.0447 - val_acc: 0.6720\n",
      "Epoch 46/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0960 - acc: 0.9681 - val_loss: 1.0656 - val_acc: 0.6676\n",
      "Epoch 47/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0854 - acc: 0.9713 - val_loss: 1.0652 - val_acc: 0.6720\n",
      "Epoch 48/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0964 - acc: 0.9662 - val_loss: 1.0920 - val_acc: 0.6720\n",
      "Epoch 49/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0876 - acc: 0.9717 - val_loss: 1.1944 - val_acc: 0.6313\n",
      "Epoch 50/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0772 - acc: 0.9739 - val_loss: 1.0870 - val_acc: 0.6618\n",
      "Epoch 51/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0907 - acc: 0.9681 - val_loss: 0.9914 - val_acc: 0.6894\n",
      "Epoch 52/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0830 - acc: 0.9691 - val_loss: 1.0132 - val_acc: 0.6836\n",
      "Epoch 53/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1047 - acc: 0.9612 - val_loss: 0.9975 - val_acc: 0.6821\n",
      "Epoch 54/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1144 - acc: 0.9554 - val_loss: 1.2149 - val_acc: 0.6328\n",
      "Epoch 55/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1055 - acc: 0.9615 - val_loss: 1.0582 - val_acc: 0.6691\n",
      "Epoch 56/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1035 - acc: 0.9619 - val_loss: 0.9723 - val_acc: 0.6981\n",
      "Epoch 57/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.0874 - acc: 0.9710 - val_loss: 1.0043 - val_acc: 0.6763\n",
      "Epoch 58/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1363 - acc: 0.9408 - val_loss: 1.3564 - val_acc: 0.5980\n",
      "Epoch 59/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1238 - acc: 0.9557 - val_loss: 1.0076 - val_acc: 0.6909\n",
      "Epoch 60/60\n",
      "2755/2755 [==============================] - 2s - loss: 0.1069 - acc: 0.9604 - val_loss: 1.0390 - val_acc: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa51f47fb90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=60 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= model.predict(X[3441:3442])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07821428,  0.92178577]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3443:3444].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
